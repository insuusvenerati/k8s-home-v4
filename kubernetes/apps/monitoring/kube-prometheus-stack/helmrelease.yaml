---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
      version: 65.8.1
  interval: 1h0m0s
  releaseName: kube-prometheus-stack
  targetNamespace: monitoring
  install:
    crds: Create
    remediation:
      retries: 5
      remediateLastFailure: true
  upgrade:
    crds: CreateReplace
    remediation:
      retries: 5
      remediateLastFailure: true
  driftDetection:
    mode: enabled
    ignore:
      - paths:
          - "/metadata/annotations/prometheus-operator-validated"
        target:
          kind: PrometheusRule
  valuesFrom:
    - kind: ConfigMap
      name: flux-kube-state-metrics-config
      valuesKey: kube-state-metrics-config.yaml
  values:
    namespaceOverride: "monitoring"
    defaultRules:
      rules:
        kubeProxy: false
        alertmanager: false
        etcd: false
        configReloaders: false
        general: false
        kubeApiserverSlos: false
        kubeControllerManager: false
        kubernetesApps: false
        kubernetesResources: false
        kubernetesStorage: false
        kubernetesSystem: false
        kubeSchedulerAlerting: false
        kubeStateMetrics: false
        network: false
        nodeExporterAlerting: false
        prometheus: false
        prometheusOperator: false
      labels:
        cluster_name: home-kubernetes
    alertmanager:
      enabled: true
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
#            selector: { }
            spec:
              storageClassName: openebs-hostpath
              accessModes: [ "ReadWriteOnce" ]
              resources:
                requests:
                  storage: 1Gi
      config:
        route:
          routes:
            - receiver: 'robusta'
              group_by: [ 'namespace' ]
              group_wait: 1s
              group_interval: 1s
              matchers:
                - severity =~ ".*"
              repeat_interval: 4h
              continue: true
          receiver: 'default-receiver'
        receivers:
          - name: 'robusta'
            webhook_configs:
              - url: 'http://robusta-runner.monitoring.svc.cluster.local/api/alerts'
                send_resolved: true #
          - name: 'default-receiver'
      ingress:
        enabled: true
        ingressClassName: internal
        annotations:
          cert-manager.io/cluster-issuer: letsencrypt-production
        hosts:
          - alertmanager.internal.${SECRET_DOMAIN}
        paths:
          - /
        tls:
          - secretName: alertmanager-general-tls
            hosts:
              - alertmanager.internal.${SECRET_DOMAIN}
    grafana:
      image:
        registry: docker.io
        repository: grafana/grafana
        tag: 11.3.0
      plugins:
        - https://storage.googleapis.com/integration-artifacts/grafana-lokiexplore-app/grafana-lokiexplore-app-latest.zip;grafana-lokiexplore-app
      sidecar:
        prune: true
        datasources:
          enabled: true
        dashboards:
          enableNewTablePanelSyntax: true
          resource: both
          folderAnnotation: grafana-dashboard-folder
          provider:
            allowUiUpdates: true
            foldersFromFilesStructure: true
      ingress:
        enabled: true
        ingressClassName: internal
        annotations:
          cert-manager.io/cluster-issuer: letsencrypt-production
          nginx.ingress.kubernetes.io/service-upstream: "false"
        hosts:
          - grafana.internal.${SECRET_DOMAIN}
        tls:
          - secretName: grafana-tls
            hosts:
              - grafana.internal.${SECRET_DOMAIN}
      persistence:
        type: pvc
        enabled: true
        size: 5Gi
        storageClasName: nfs-client-ssd
    kubeApiServer:
      enabled: true
      tlsConfig:
        insecureSkipVerify: true
    kubelet:
      enabled: true
    kubeControllerManager:
      enabled: true
      service:
        enabled: true
        port: 10257
        targetPort: 10257
        selector:
          k8s-app: kube-controller-manager
      serviceMonitor:
        insecureSkipVerify: true
    coreDns:
      enabled: true
      service:
        enabled: true
        selector:
          k8s-app: kube-dns
    kubeEtcd:
      enabled: true
      endpoints:
        - 192.168.1.135
      service:
        enabled: true
    kubeScheduler:
      enabled: true
      service:
        enabled: true
        port: 10259
        targetPort: 10259
        selector:
          k8s-app: kube-scheduler
      serviceMonitor:
        insecureSkipVerify: true
    kubeProxy:
      enabled: false
      service:
        enabled: true
        selector:
          k8s-app: kube-proxy
    prometheusOperator:
      enabled: true
      networkPolicy:
        enabled: false
        flavor: cilium
    prometheus:
      enabled: true
      networkPolicy:
        enabled: false
        flavor: cilium
      thanosService:
        enabled: false
      thanosServiceMonitor:
        enabled: false
      prometheusSpec:
        enableRemoteWriteReceiver: true
        persistentVolumeClaimRetentionPolicy:
          whenDeleted: Retain
          whenScaled: Retain
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: openebs-hostpath
              accessModes: [ "ReadWriteOnce" ]
              resources:
                requests:
                  storage: 10Gi
        retention: 365d
        resources:
          requests:
            cpu: 200m
            memory: 200Mi
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        ruleSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        scrapeConfigSelectorNilUsesHelmValues: false
        additionalScrapeConfigs:
          - job_name: 'adguard'
            static_configs:
              - targets: [ '192.168.1.164:9618' ]
          - job_name: 'qbittorrent'
            static_configs:
              - targets: ['192.168.1.230:8000']
